{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import itertools\n",
    "import os\n",
    "import marsilea as ma\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['segemehl',\n",
       " 'find_circ',\n",
       " 'dcc',\n",
       " 'psirc',\n",
       " 'circexplorer2',\n",
       " 'ciriquant',\n",
       " 'ciri2']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUANTIFICATION_DIR = \"quantification\"\n",
    "OUT_DIR = \"../chapters/4_results_and_discussion/figures/quantification\"\n",
    "tools = [tool_csv[:-4] for tool_csv in os.listdir(QUANTIFICATION_DIR)]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_locstring(locstring: str):\n",
    "    parts = locstring.split(\":\")\n",
    "    chrom, coords, strand = parts if len(parts) == 3 else (parts[0], parts[1], \".\")\n",
    "    chrom = chrom[len(\"circ_\"):] if chrom.startswith(\"circ_\") else chrom\n",
    "    start, end = coords.split(\"-\")\n",
    "    return {\"chr\": chrom, \"start\": int(start), \"end\": int(end), \"strand\": strand}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_dfs = []\n",
    "\n",
    "for tool in tools:\n",
    "    file = os.path.join(QUANTIFICATION_DIR, f\"{tool}.tsv\")\n",
    "    df = pl.scan_csv(file, separator=\"\\t\")\n",
    "    df = df.with_columns(tool=pl.lit(tool))\n",
    "    df = df.drop(\"gene_id\")\n",
    "    df = df.rename({(\"tx\" if tool == \"psirc\" else \"circ_id\"): \"id\"})\n",
    "    tool_dfs.append(df)\n",
    "\n",
    "samples = tool_dfs[0].drop(\"id\", \"tool\").collect_schema()\n",
    "\n",
    "tool_dfs = [df.select(\"id\", \"tool\", *samples).with_columns(**{sample: pl.col(sample).cast(int) for sample in samples}) for df in tool_dfs]\n",
    "\n",
    "df = pl.concat(tool_dfs)\n",
    "\n",
    "df = df.with_columns(location=pl.col(\"id\").map_elements(parse_locstring, return_dtype=pl.Struct))\n",
    "df = df.with_columns(\n",
    "    chr=pl.col(\"location\").map_elements(lambda x: x[\"chr\"], return_dtype=str),\n",
    "    start=pl.col(\"location\").map_elements(lambda x: x[\"start\"], return_dtype=int),\n",
    "    end=pl.col(\"location\").map_elements(lambda x: x[\"end\"], return_dtype=int),\n",
    "    strand=pl.col(\"location\").map_elements(lambda x: x[\"strand\"], return_dtype=str)\n",
    ").drop(\"location\")\n",
    "\n",
    "df = df.unpivot(on=samples, index=[\"chr\", \"start\", \"end\", \"strand\", \"id\", \"tool\"], variable_name=\"sample\", value_name=\"count\")\n",
    "df = df.select(\"chr\", \"start\", \"end\", \"tool\", \"sample\", \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.group_by(\"chr\", \"start\", \"end\", \"tool\", \"sample\").agg(count=pl.col(\"count\").sum())\n",
    "df = df.collect().lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df: pl.LazyFrame, max_shift: int, fillnull: bool):\n",
    "    df = df.sort(\"chr\", \"end\"  ).with_columns(end_group  =pl.col(\"end\"  ).diff().fill_null(0).gt(max_shift).cum_sum())\n",
    "    df = df.sort(\"chr\", \"start\").with_columns(start_group=pl.col(\"start\").diff().fill_null(0).gt(max_shift).cum_sum())\n",
    "\n",
    "    group_cols = [\"chr\", \"sample\", \"start_group\", \"end_group\"]\n",
    "    df = df.group_by(group_cols + [\"start\", \"end\"]).len().join(df, on=group_cols, how=\"inner\")\n",
    "    df = df.select(\"chr\", \"start\", \"end\", \"sample\", \"start_right\", \"end_right\", \"tool\", \"count\")\n",
    "\n",
    "    df = df.filter((pl.col(\"start\") - pl.col(\"start_right\")).abs() <= max_shift)\n",
    "    df = df.filter((pl.col(\"end\") - pl.col(\"end_right\")).abs() <= max_shift)\n",
    "    df = df.collect().pivot(on=\"tool\", values=\"count\", index=[\"chr\", \"start\", \"end\", \"sample\"], aggregate_function=\"sum\", sort_columns=True).lazy()\n",
    "    df = df.collect().to_pandas().set_index([\"chr\", \"start\", \"end\", \"sample\"])\n",
    "\n",
    "    if fillnull:\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "    quantification_tools = [\"ciriquant\", \"psirc\"]\n",
    "    detection_tools = [tool for tool in tools if tool not in quantification_tools]\n",
    "    df_detection = df[detection_tools]\n",
    "    df_quantification = df[quantification_tools]\n",
    "    df_agg = pd.DataFrame(index=df.index)\n",
    "    df_agg[\"sum\"]    = df_detection.sum(axis=1)\n",
    "    df_agg[\"min\"]    = df_detection.min(axis=1)\n",
    "    df_agg[\"max\"]    = df_detection.max(axis=1)\n",
    "    df_agg[\"median\"] = df_detection.median(axis=1)\n",
    "\n",
    "    df_plot = pd.concat([df_detection, df_agg, df_quantification], axis=1)\n",
    "    df_plot\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr = df_plot.corr()\n",
    "\n",
    "    # Invert column order\n",
    "    corr = corr.iloc[::-1]\n",
    "\n",
    "    h = ma.Heatmap(corr, annot=True, fmt=\".2f\")\n",
    "\n",
    "    categories = [\"Detection\", \"Aggregations\", \"Quant.\"]\n",
    "    colors = [\"#54F0F0\", \"#F05454\", \"#F0F054\"]\n",
    "\n",
    "    h.group_cols([categories[0] if group in detection_tools else categories[2] if group in quantification_tools else categories[1] for group in corr.columns], order=categories)\n",
    "    h.group_rows([categories[0] if group in detection_tools else categories[2] if group in quantification_tools else categories[1] for group in corr.index], order=categories[::-1])\n",
    "    h.add_bottom(ma.plotter.Chunk(categories, fill_colors=colors), pad=0.05)\n",
    "    h.add_bottom(ma.plotter.Labels(corr.columns), pad=0.05)\n",
    "    h.add_left(ma.plotter.Chunk(categories[::-1], fill_colors=colors[::-1]), pad=0.05)\n",
    "    h.add_left(ma.plotter.Labels(corr.index), pad=0.05)\n",
    "\n",
    "    h.add_legends(\"right\")\n",
    "    h.add_title(\"Correlation between detection tools and aggregations\")\n",
    "    h.save(os.path.join(OUT_DIR, f\"correlation_heatmap_{max_shift}_{\"0\" if fillnull else \"na\"}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_shift, fillnull in itertools.product([0, 1, 3, 5, 10], [True, False]):\n",
    "    plot(df, max_shift, fillnull)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-plots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
