{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import marsilea as ma\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['segemehl',\n",
       " 'find_circ',\n",
       " 'dcc',\n",
       " 'psirc',\n",
       " 'circexplorer2',\n",
       " 'ciriquant',\n",
       " 'ciri2']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUANTIFICATION_DIR = \"quantification\"\n",
    "OUT_DIR = \"../chapters/4_results_and_discussion/figures/quantification\"\n",
    "tools = [tool_csv[:-4] for tool_csv in os.listdir(QUANTIFICATION_DIR)]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_locstring(locstring: str):\n",
    "    parts = locstring.split(\":\")\n",
    "    chrom, coords, strand = parts if len(parts) == 3 else (parts[0], parts[1], \".\")\n",
    "    chrom = chrom[len(\"circ_\"):] if chrom.startswith(\"circ_\") else chrom\n",
    "    start, end = coords.split(\"-\")\n",
    "    return {\"chr\": chrom, \"start\": int(start), \"end\": int(end), \"strand\": strand}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_dfs = []\n",
    "\n",
    "for tool in tools:\n",
    "    file = os.path.join(QUANTIFICATION_DIR, f\"{tool}.tsv\")\n",
    "    df = pl.scan_csv(file, separator=\"\\t\")\n",
    "    df = df.with_columns(tool=pl.lit(tool))\n",
    "    df = df.drop(\"gene_id\")\n",
    "    df = df.rename({(\"tx\" if tool == \"psirc\" else \"circ_id\"): \"id\"})\n",
    "    tool_dfs.append(df)\n",
    "\n",
    "samples = tool_dfs[0].drop(\"id\", \"tool\").collect_schema()\n",
    "\n",
    "tool_dfs = [df.select(\"id\", \"tool\", *samples).with_columns(**{sample: pl.col(sample).cast(float) for sample in samples}) for df in tool_dfs]\n",
    "tool_dfs = [df.with_columns(**{sample: pl.col(sample) / pl.col(sample).sum() for sample in samples}) for df in tool_dfs]\n",
    "\n",
    "df = pl.concat(tool_dfs)\n",
    "\n",
    "df = df.with_columns(location=pl.col(\"id\").map_elements(parse_locstring, return_dtype=pl.Struct))\n",
    "df = df.with_columns(\n",
    "    chr=pl.col(\"location\").map_elements(lambda x: x[\"chr\"], return_dtype=str),\n",
    "    start=pl.col(\"location\").map_elements(lambda x: x[\"start\"], return_dtype=int),\n",
    "    end=pl.col(\"location\").map_elements(lambda x: x[\"end\"], return_dtype=int)\n",
    ").drop(\"location\")\n",
    "\n",
    "df = df.unpivot(on=samples, index=[\"chr\", \"start\", \"end\", \"id\", \"tool\"], variable_name=\"sample\", value_name=\"count\")\n",
    "df = df.select(\"chr\", \"start\", \"end\", \"tool\", \"sample\", \"count\")\n",
    "df = df.filter(pl.col(\"count\").is_not_null() & (pl.col(\"count\") > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_427_062, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>chr</th><th>start</th><th>end</th><th>tool</th><th>sample</th><th>count</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;chr1&quot;</td><td>12856302</td><td>12856922</td><td>&quot;segemehl&quot;</td><td>&quot;antiHormonal_20m_ESR1_tamoxife…</td><td>0.000645</td></tr><tr><td>&quot;chr1&quot;</td><td>16460044</td><td>16464434</td><td>&quot;segemehl&quot;</td><td>&quot;antiHormonal_20m_ESR1_tamoxife…</td><td>0.000645</td></tr><tr><td>&quot;chr1&quot;</td><td>34223096</td><td>34223225</td><td>&quot;segemehl&quot;</td><td>&quot;antiHormonal_20m_ESR1_tamoxife…</td><td>0.000645</td></tr><tr><td>&quot;chr1&quot;</td><td>38146648</td><td>38147548</td><td>&quot;segemehl&quot;</td><td>&quot;antiHormonal_20m_ESR1_tamoxife…</td><td>0.000645</td></tr><tr><td>&quot;chr1&quot;</td><td>38573986</td><td>38576027</td><td>&quot;segemehl&quot;</td><td>&quot;antiHormonal_20m_ESR1_tamoxife…</td><td>0.000645</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;chrX&quot;</td><td>151440420</td><td>151444714</td><td>&quot;ciri2&quot;</td><td>&quot;aging_18m_CYP19A1_no_1&quot;</td><td>0.000272</td></tr><tr><td>&quot;chrX&quot;</td><td>156355855</td><td>156374551</td><td>&quot;ciri2&quot;</td><td>&quot;aging_18m_CYP19A1_no_1&quot;</td><td>0.000272</td></tr><tr><td>&quot;chrX&quot;</td><td>158068262</td><td>158100998</td><td>&quot;ciri2&quot;</td><td>&quot;aging_18m_CYP19A1_no_1&quot;</td><td>0.000544</td></tr><tr><td>&quot;chrX&quot;</td><td>158599573</td><td>158600294</td><td>&quot;ciri2&quot;</td><td>&quot;aging_18m_CYP19A1_no_1&quot;</td><td>0.000272</td></tr><tr><td>&quot;chrX&quot;</td><td>161704195</td><td>161719801</td><td>&quot;ciri2&quot;</td><td>&quot;aging_18m_CYP19A1_no_1&quot;</td><td>0.000272</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_427_062, 6)\n",
       "┌──────┬───────────┬───────────┬──────────┬─────────────────────────────────┬──────────┐\n",
       "│ chr  ┆ start     ┆ end       ┆ tool     ┆ sample                          ┆ count    │\n",
       "│ ---  ┆ ---       ┆ ---       ┆ ---      ┆ ---                             ┆ ---      │\n",
       "│ str  ┆ i64       ┆ i64       ┆ str      ┆ str                             ┆ f64      │\n",
       "╞══════╪═══════════╪═══════════╪══════════╪═════════════════════════════════╪══════════╡\n",
       "│ chr1 ┆ 12856302  ┆ 12856922  ┆ segemehl ┆ antiHormonal_20m_ESR1_tamoxife… ┆ 0.000645 │\n",
       "│ chr1 ┆ 16460044  ┆ 16464434  ┆ segemehl ┆ antiHormonal_20m_ESR1_tamoxife… ┆ 0.000645 │\n",
       "│ chr1 ┆ 34223096  ┆ 34223225  ┆ segemehl ┆ antiHormonal_20m_ESR1_tamoxife… ┆ 0.000645 │\n",
       "│ chr1 ┆ 38146648  ┆ 38147548  ┆ segemehl ┆ antiHormonal_20m_ESR1_tamoxife… ┆ 0.000645 │\n",
       "│ chr1 ┆ 38573986  ┆ 38576027  ┆ segemehl ┆ antiHormonal_20m_ESR1_tamoxife… ┆ 0.000645 │\n",
       "│ …    ┆ …         ┆ …         ┆ …        ┆ …                               ┆ …        │\n",
       "│ chrX ┆ 151440420 ┆ 151444714 ┆ ciri2    ┆ aging_18m_CYP19A1_no_1          ┆ 0.000272 │\n",
       "│ chrX ┆ 156355855 ┆ 156374551 ┆ ciri2    ┆ aging_18m_CYP19A1_no_1          ┆ 0.000272 │\n",
       "│ chrX ┆ 158068262 ┆ 158100998 ┆ ciri2    ┆ aging_18m_CYP19A1_no_1          ┆ 0.000544 │\n",
       "│ chrX ┆ 158599573 ┆ 158600294 ┆ ciri2    ┆ aging_18m_CYP19A1_no_1          ┆ 0.000272 │\n",
       "│ chrX ┆ 161704195 ┆ 161719801 ┆ ciri2    ┆ aging_18m_CYP19A1_no_1          ┆ 0.000272 │\n",
       "└──────┴───────────┴───────────┴──────────┴─────────────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.collect().lazy()\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantification_tools = [\"ciriquant\", \"psirc\"]\n",
    "detection_tools = [\"segemehl\", \"find_circ\", \"ciri2\", \"dcc\", \"circexplorer2\"]\n",
    "\n",
    "\n",
    "def plot(df: pl.LazyFrame, max_shift: int, fillnull: bool):\n",
    "    df = df.sort(\"chr\", \"end\"  ).with_columns(end_group  =pl.col(\"end\"  ).diff().fill_null(0).gt(max_shift).cum_sum())\n",
    "    df = df.sort(\"chr\", \"start\").with_columns(start_group=pl.col(\"start\").diff().fill_null(0).gt(max_shift).cum_sum())\n",
    "\n",
    "    group_cols = [\"chr\", \"start_group\", \"end_group\"]\n",
    "    df = df.group_by(group_cols + [\"start\", \"end\"]).len().join(df, on=group_cols, how=\"inner\")\n",
    "    df = df.select(\"chr\", \"start\", \"end\", \"sample\", \"start_right\", \"end_right\", \"tool\", \"count\")\n",
    "\n",
    "    df = df.filter((pl.col(\"start\") - pl.col(\"start_right\")).abs() <= max_shift)\n",
    "    df = df.filter((pl.col(\"end\") - pl.col(\"end_right\")).abs() <= max_shift)\n",
    "    df = df.collect().pivot(on=\"tool\", values=\"count\", index=[\"chr\", \"start\", \"end\", \"sample\"], aggregate_function=\"sum\", sort_columns=True).lazy()\n",
    "    df = df.collect().to_pandas().set_index([\"chr\", \"start\", \"end\", \"sample\"])\n",
    "\n",
    "    if fillnull:\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "    df_detection = df[detection_tools]\n",
    "    df_quantification = df[quantification_tools]\n",
    "    df_agg = pd.DataFrame(index=df.index)\n",
    "    df_agg[\"sum\"]    = df_detection.sum(axis=1)\n",
    "    df_agg[\"min\"]    = df_detection.min(axis=1)\n",
    "    df_agg[\"max\"]    = df_detection.max(axis=1)\n",
    "    df_agg[\"mean\"]   = df_detection.mean(axis=1)\n",
    "    df_agg[\"median\"] = df_detection.median(axis=1)\n",
    "\n",
    "    df_plot = pd.concat([df_detection, df_agg, df_quantification], axis=1)\n",
    "\n",
    "    # Calculate the correlation matrix\n",
    "    corr = df_plot.corr()\n",
    "\n",
    "    # Invert column order\n",
    "    corr = corr.iloc[::-1]\n",
    "\n",
    "    h = ma.Heatmap(corr, annot=True, fmt=\".2f\")\n",
    "\n",
    "    categories = [\"Detection\", \"Aggregations\", \"Quant.\"]\n",
    "    colors = [\"#54F0F0\", \"#F05454\", \"#F0F054\"]\n",
    "\n",
    "    h.group_cols([categories[0] if group in detection_tools else categories[2] if group in quantification_tools else categories[1] for group in corr.columns], order=categories)\n",
    "    h.group_rows([categories[0] if group in detection_tools else categories[2] if group in quantification_tools else categories[1] for group in corr.index], order=categories[::-1])\n",
    "    h.add_bottom(ma.plotter.Chunk(categories, fill_colors=colors), pad=0.05)\n",
    "    h.add_bottom(ma.plotter.Labels(corr.columns), pad=0.05)\n",
    "    h.add_left(ma.plotter.Chunk(categories[::-1], fill_colors=colors[::-1]), pad=0.05)\n",
    "    h.add_left(ma.plotter.Labels(corr.index), pad=0.05)\n",
    "\n",
    "    h.add_legends(\"right\")\n",
    "    h.add_title(f\"Correlation matrix; max shift: {max_shift} nt; {\"Missing as 0\" if fillnull else \"Missing as NaN\"}\")\n",
    "    h.save(os.path.join(OUT_DIR, f\"correlation_heatmap_{max_shift}_{\"0\" if fillnull else \"na\"}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:38,  9.86s/it]\n"
     ]
    }
   ],
   "source": [
    "for max_shift, fillnull in tqdm(itertools.product([0, 1, 3, 5, 10], [True, False])):\n",
    "    plot(df, max_shift, fillnull)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-plots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
